\section{Загальна характеристика задач прийняття рішень. Основні компоненти задач прийняття рішень.}\marginpar{\framebox{12.02.2014}}
\subsection{Основні компоненти задач прийняття рішень}
\begin{itemize}	
\item {\bf Суб’єкт} - особа, або група осіб, який приймають рішення та несуть повну відповідальність за прийняте рішення;
\item {\bf Рішення (стратегія)} - ціль прийняття рішень. Позначення \vx;
\item {\bf Вихідні змінні задачі} - результати прийнятої стратегії. Позначення \vy;
\item {\bf Неконтрольовані змінні} - змінні, значення яких не залежить від особи, що приймає рішення. Вони є двох видів:
\begin{itemize}
\item {\bf Внутрішні змінні} - постійні в даній задачі, параметри задачі. Позначення $p_k$;
\item {\bf Зовнішні змінні} - змінні, які можуть змінюватися. Також називаються збудження. Позначення $\Omega$.
\end{itemize}
\item {\bf Критерій або цільова функція} - ціль ефективності. Якщо в задачі багато критеріїв, вона називається {\bf багатокритерійною};
\item {\bf Обмеження} - обмеження даної задачі. Вони можуть бути на ресурси системи, на фінанси, на людські ресурси та на час;
\item {\bf Математична модель} - математична модель задачі прийняття рішень.
\end{itemize} 
\begin{exs}[Приклад математичної моделі]
\cj - прибуток від продажу $j$-го продукту.\\
\aij - норма витрат $i$-го підприємства на $j$-тий продукт\\
\bi - об’єм ресурсу на $i$-тому підприємстві.\\
\begin{equation}
\max\set{\suml_{j=1}^n \cj \xj}
\end{equation}
Обмеження:
\begin{eqnarray}
\suml_{j=1}^n \aij \xj &\leq  \bi; &\ifom \\
\xj & \geq 0; &\jfon
\end{eqnarray}
\end{exs}
Задачі прийняття рішень діляться на такі класи:
\begin{itemize}
\item Задачі, в умовах визначеності (задачі ДО);
\item Задачі з впливом випадкових факторів (задачі прийняття рішень в умові риску). Для них задано $\set{p(y|x)}$;
\item Якщо зв’язок між прийнятим рішенням та наслідком не відомі, то це задача нестатистичної визначеності;
\item Якщо в прийнятті рішень наявні кілька осіб, інтереси яких різні та, можливо, навіть протилежні, це задачі прийняття рішень в умовах конфлікту;
\item Задачі, які є кілька критеріїв оптимальності. Такі задачі називаються багатокритерійними. Тут необхідно шукати деякий компроміс, оскільки рішення, яке б дало оптимальний результат за всіма критеріями у багатьох випадках не існує.
\end{itemize}
Задачі, що розв’язує теорія прийняття рішень поділяються на два типи:
\begin{itemize}
\item Задачі прийняття рішень в умовах випадкових факторів називаються {\bf задачі стохастичного програмування};
\item Задач прийняття рішень в умовах невизначеності мають назву {\bf задачі нечіткого програмування}.
\end{itemize}
\section{Задачі стохастичного програмування}
{\bf Задачі стохастичного програмування} - це клас задач, в яких присутні випадкові фактори.\\
\begin{exs}[Приклад стохастичної задачі]
\begin{eqnarray}
\min f(x,\omega)&\\
g_i(x,\omega) \leq b_i,&\ifom
\end{eqnarray}
$\omega\in\Omega$ - множина станів середовища.
\end{exs}
В такому вигляді, функції $f(x,\omega)$ та $g_i(x,\omega)$ випадкові функції, оптимізувати які немає сенсу. Тому потрібно перейти до яких численних характеристик.
\subsection{М-модель стохастичного програмування}
Ідея полягає в тому, щоб брати математичне очікування від функцій.\\
Критерій:
\begin{equation}
\mEt{f(x,\omega)}=F(x)
\end{equation}
Обмеження:
\begin{equation}
\mEt{g_i(x,\omega)}=G_i(x),\ifom
\end{equation}
\subsection{P-модель стохастичного програмування}
Модель, в якій числові функції знаходяться через ймовірності.\\
Нехай $c$ - максимальні затрати.\\
Тоді модель перетвориться на:\\
Критерій:
\begin{equation}
\min\set{\mP\set{f(x,\omega)\geq c}}
\end{equation}
Обмеження:
\begin{equation}
\mP\set{g_i(x,\omega)\leq \alpha_i};\ifom
\end{equation}
$\alpha\in\bb{0,1}$ - задані.
\subsection{MP-модель стохастичного програмування}
Критерій:
\begin{equation}
\mEt{f(x,\omega)}=F(x)
\end{equation}
Обмеження:
\begin{equation}
\mP\set{g_i(x,\omega)\leq \alpha_i};\ifom
\end{equation}
\subsection{PM-модель стохастичного програмування}
Критерій:
\begin{equation}
\min\set{\mP\set{f(x,\omega)\geq c}}
\end{equation}
Обмеження:
\begin{equation}
\mEt{g_i(x,\omega)}=G_i(x),\ifom
\end{equation}
\subsection{Зв’язок між P-моделю та M-моделю}
Існує можливість перейти від P-моделі до еквівалентної M-моделі наступним чином.\\
Введемо функції:
\begin{equation}
h_0(x,\omega)=\system{1, f(x,\omega)\geq c\\0}
\end{equation}
\begin{equation}
h_i(x,\omega)=\system{1, g_i(x,\omega)\leq b_i\\0};\ifom
\end{equation}
Тоді можливий такий перехід:\\
$\mP\set{f(x,\omega)\geq c}=\mEt{h_0(x,\omega)}$\\
$\mP\set{g_i(x,\omega)\leq b_i} = \mEt{h_i(x,\omega)};\ifom$
\subsection{Класи задач стохастичного програмування}
В залежності від того, якою інформацією володіє ОПР (особа, що приймає рішення) задачі стохастичного програмування діляться на:
\begin{itemize}
\item Задачі перспективного СП - задачі, що виникають коли ОПР не може виміряти випадкові фактори. Наприклад, задачі випуску нової продукції. Такого плану задачі частіше за все виникають при стратегічному та перспективному плануванні. Або в задачах проектування. В такому випадку ми використовуємо увесь можливий спектр значень випадкових параметрів;
\item Задачі оперативного СП - задачі, в яких ОПР має можливість провести спостереження та виміряти значення випадкових факторів, а після цього прийняти рішення. Це задачі діагностики.
\end{itemize}
Методи стохастичного програмування поділяються на:
\begin{itemize}
\item Прямі методи - це метод, який використовується для розв’язку оперативного СП. Частіше за все являє собою деякий ітеративний процес, в якому ОПР, вимірявши значення випадкових факторів, приймає рішення. Через деякий час ОПР спостерігає результати рішення і виміряє нові випадкові фактори;
\item Непрямі методи - це розв’язок задачі перспективного СП, шляхом приведення ймовірнісного еквіваленту до задачі нелінійного програмування.
\end{itemize}
\begin{exs}[Модель прямого методу]
\begin{tikzpicture}
\node[rectangle,draw] (c1) {$f(x,\omg)$};
\node[rectangle,draw,below=1.5cm of c1] (c2) {ОПР};
\node[right=2cm of c1] (c3) {$f(x_1,\omg_1)$};
\draw (c2) -- ++(0,-0.8) -- ++(-1.5,0) -- ++(0,4) -- ++(1.5,0)node[above]{$\omg_1$}[->] -- (c1);
\draw[white] (c3) -- ++(-1.5,0) [black,->] |- (c2);
\node[right=1cm of c2.210]{$\set{x_1(\nomg1),\ldots,x_s(\nomg s)},s\in\mN$};
\path[->]
(c2) edge node[right] {$x_{s+1}(\omg_{s+1})$} (c1)
(c1) edge (c3)
;
\end{tikzpicture} \\
$x_s(\omega_s)$ - випадкова послідовність.\\
Тоді критерій оптимальності: $\liml_{s\to\inf}x_s(\omega_s)=x^*$ - аргумент F(x).
\end{exs}
\section{Одноетапні задачі стохастичного програмування}
{\bf Одноетапні задачі} - відносяться до задачі перспективного СП і розв’язуються непрямими методами.\\
V-модель:
\begin{eqnarray}
\min\set{\mDt{f(x,\omega)}}&\\
\mEt{g_i(x,\omega)} \leq b_i;&\ifom
\end{eqnarray}
В загальному випадку побудова детермінованого еквіваленту ймовірнісної задачі являє собою досить важку задачу. Тому, вона розв’язується лише для простих розподілів.
\subsection{Лінійні задачі стохастичного програмування}
\begin{eqnarray}
&\max\set{\mEt{\suml_{j=1}^n c_j(\omega)x_j}} \\
&\mP\set{\suml_{j=1}^n \aij(\omg)\xj\leq \bi(\omega)};&\ifom \\
&\xj \geq 0;&\ifom
\end{eqnarray}
Позначимо $\mEt{c_j(\omega)} = \hcj$\\
\subsubsection{Випадок нормального розподілу}\label{tr:1:1}
Нехай $p(\aij)\sim\aleph\cb{\haij,\Sigma_{ij}^2}$, $p(\bi)\sim\aleph\cb{\hbi,\Theta_i^2}$\\
Також всі ці штуки між собою статистично незалежні.\\
\begin{eqnarray}
&{\suml_{j=1}^n\aij\xj\leq\bi} = \mP\set{\suml_{j=1}^n\aij\xj-\bi=\delta_i(x)\leq 0}\\
&\mEt{\delta_i(x)} = \suml_{j=1}^n \haij\xj-\hbi\label{tr:1:2}\\
&\mDt{\delta_i(x)} = \sigma_i^2(x) = \suml_{j-1}^n \Sigma_{ij}^2 \xj^2 + \Theta_i^2\\
&\mP\set{\delta_i(x)}\sim\aleph\cb{\hdeli(x),\sigma_i^2(x)}\\
&\mP\set{\delta_i(x)\leq 0} = \cfrac1{\sqrt{2\pi}\sigma_i(x)} \intmz e^{-\frac{\xi_i - \hdeli(x)}{2\sigma_i^2(x)}}\dxi
\end{eqnarray}
Заміна:$\cfrac{\xi_i - \hdeli(x)}{2\sigma_i^2(x)} = v(x)$\\
\begin{eqnarray}
&\mP\set{\delta_i(x)\leq 0} = \frac1{2\pi} \intl_{-\infty}^t e^{-v^2}2 \dv, t = -\cfrac{\hdeli(x)}{\sigma_i(x)}\\
&\Phi(t) = \Phi\cb{-\cfrac{\hdeli(x)}{\sigma_i(x)}} \geq \alpha_i\\
&-\cfrac{\hdeli(x)}{\sigma_i(x)} =  \Phi^{-1}\cb{\alpha_i}\\
&\delta_i(x)+\Phi^{-1}\cb{\alpha_i}\sigma(x)\leq 0\label{tr:1:3}\\
&\suml_{j=1}^n\haij\xj+\Phi^{-1}\cb{\al_i}\cb{\suml_{j=1}^n \aij^2\xj^2+\Theta^2_i}^{\frac12} \leq\hbi\label{tr:1:4}
\end{eqnarray}
В рівнянні \eqref{tr:1:4} другий член рівняння дорівнює нулю, якщо величина невипадкова, а в інших випадках вказує на запас риску.\\
Якщо $\alpha_i\geq 0.5$ то $\Phi^{-1}\cb{\alpha_i}\geq0$ і маємо задачу випуклого програмування.\\
Тепер змінимо знак:
\begin{eqnarray}
&\mP{\suml_{j=1}^n \aij(\omega)\xj\geq \bi(\omega)};\ifom\\
&\mP{\suml_{j=1}^n \aij(\omega)\xj\geq \bi(\omega)}  = \mP\set{\delta_i(x) = \bi - \suml_{j=1}^n \aij\xj\leq0}
\end{eqnarray}
Подальше аналогічно. Проробив усі пункти \eqref{tr:1:2}-\eqref{tr:1:3} отримаємо наступним детермінований еквівалент:\\
\begin{equation}
\suml_{j=1}^n \haij\xj - \Phi^{-1}(\alpha_i)\cb{\suml_{j=1}^n \aij^2\xj^2+\Theta_i^2}^{\frac12}\geq \hbi
\end{equation}
\subsubsection{Випадок рівномірного розподілу}
Нехай \aij мають рівномірний розподіл: 
\begin{equation}
\mP\set{\aij} = \system{\frac1{\delta_{ij}-\gamma_{ij}},\aij\in\bb{\gamma_{ij},\delta_{ij}}\\0}\\
\end{equation}
Якщо число додатків більше 3, то можна використовувати центральну граничну теорему.\\
\begin{eqnarray}
&\max \mEt{\suml_{j=1}^n c_j \cb{\omg} \xj = \sum \bar{\cj} \xj}\\
&\mP\set{\suml_{j=1}^n\aij \xj \leq \bi} \geq \al_i\\
&\suml_{j=1}^n \bar{\aij} \xj + \Phi^{-1} \cb{\suml_{j=1}^n \sigma^2_{ij} \xj^2 +\Theta_i^2}^{\frac12} \leq \bar{\bi}\label{tr:1:5}
\end{eqnarray}
$\aij$ корелюється з $\bi$ і $a_{ik}$
\begin{eqnarray}
&V_{ijk} = \mEt{\cb{\aij-\bar{\aij}}\cb{a_{ik} - \bar{a_{ik}}}}\\
&\mEt{\cb{\aij - \bar{\aij}}\cb{\bi - \bar{\bi}}} = \nu_{ij}\\
&\mDt{\suml_{j=1}^n \aij \xj - \bi} = \suml_{k=1}^n \suml_{j=1}^n V_{ijk} \xj x_k - 2\suml_{j=1}^n \nu_{ij} \xj + \Theta^2_i
\end{eqnarray}
З \eqref{tr:1:5} отримуємо:
\begin{equation}
\suml_{j=1}^n \bar{\aij} \xj + \Phi^{-1} \cb{\suml_{k=1}^n \suml_{j=1}^n V_{ijk} \xj x_k - 2\suml_{j=1}^n \nu_{ij} \xj + \Theta^2_i}^{\frac12} \leq \bar{\bi}
\end{equation}